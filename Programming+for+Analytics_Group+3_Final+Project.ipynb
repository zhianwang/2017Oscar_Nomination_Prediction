{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming for Analytics_Group 3_Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis for Movies in 2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import twitter\n",
    "import tweepy\n",
    "import textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getAuthData():\n",
    "    import csv\n",
    "    with open('/home/zwang/1-ProgrammingForBA/FinalProject/authdata/authdataQ1.csv', 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        your_list = list(reader)\n",
    "\n",
    "    authdata = {}   \n",
    "    for element in your_list:\n",
    "        authdata[element[0]] = element[1]\n",
    "    print(authdata)\n",
    "\n",
    "    return authdata\n",
    "\n",
    "def remove_punctuation(s):\n",
    "    #to remove the punctuations in the twitter#\n",
    "    punctuation = \"!\\\"#$%&'()*+,-./:;<=>?@[\\\\]^_`{|}~\"\n",
    "    s_sans_punct = \"\"\n",
    "    for letter in s:\n",
    "        if (letter not in punctuation) and (letter in \"abcdefghijklmnopqrstuvwxyz \"):\n",
    "            s_sans_punct += letter\n",
    "    return s_sans_punct\n",
    "\n",
    "def getLowerCaseText(status_texts):\n",
    "    #transfer the twitter into lowercase twitter#\n",
    "    lowered_texts = []\n",
    "    for texts in status_texts:\n",
    "        try: \n",
    "            mytext = str(texts.lower())\n",
    "            lowered_texts.append(mytext)\n",
    "        except:\n",
    "            pass\n",
    "    return lowered_texts\n",
    "\n",
    "def remove_stopwords(lowered_text):\n",
    "    #remove the stopwords in the twitter, u can define the stopwords list by yourself#\n",
    "    #self define stopword list\n",
    "    stopword=['and','the','to','of','her','it','in','you','she','for']\n",
    "    #stop = stopwords.words('english') + ['rt', 'via']\n",
    "    good_words=[]\n",
    "    good_text= [text for text in lowered_text if text not in stopword]\n",
    "    good_words.append(good_text)\n",
    "    #print(good_words)\n",
    "    return good_words\n",
    "\n",
    "def getCleanedTweets(lowered_texts):\n",
    "    cleanedTweets = []\n",
    "    for text in lowered_texts:\n",
    "        wordlist = str(text).split()\n",
    "        wordlist_nopun = [ str(remove_punctuation(for_a_word)) for for_a_word in wordlist ]\n",
    "        cleanedTweets.append(wordlist_nopun)\n",
    "    return cleanedTweets\n",
    "\n",
    "def getScore(fileName):\n",
    "    \n",
    "    with open(\"/home/zwang/1-ProgrammingForBA/FinalProject/Twitter text/2012/\"+fileName,'r') as f:\n",
    "        tweetTexts = f.readlines()\n",
    "    lowered_texts = getLowerCaseText(tweetTexts)\n",
    "    lowered_texts = remove_stopwords(lowered_texts)\n",
    "    cleanedTweets = getCleanedTweets(lowered_texts)\n",
    "    sentimentList = GetSentimentScores(cleanedTweets)\n",
    "    score = sum(sentimentList)/len(sentimentList)*50+50\n",
    "    return(score)\n",
    "\n",
    "def GetSentimentScores(cleanedTweets):\n",
    "    sentiment = []\n",
    "    for eachTweet in cleanedTweets:\n",
    "        analysis = textblob.TextBlob(str(eachTweet))   \n",
    "        sentiment.append(analysis.sentiment.polarity)\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTweepyData(searchTerm, fileName):\n",
    "    auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    auth.set_access_token(OAUTH_TOKEN,OAUTH_TOKEN_SECRET)\n",
    "    api = tweepy.API(auth)    \n",
    "    \n",
    "    tweet_cursor = tweepy.Cursor(api.search,q=searchTerm)\n",
    "    \n",
    "    tweetTexts = []\n",
    "    n=0\n",
    "    for tweet in tweet_cursor.items():    \n",
    "        if n <= 1000:\n",
    "            tweetTexts.append(tweet.text) \n",
    "            n += 1\n",
    "        else: \n",
    "            break\n",
    "    \n",
    "    with open(\"/home/zwang/1-ProgrammingForBA/FinalProject/Twitter text/2012/\"+fileName,'a') as f:\n",
    "        f.writelines(tweetTexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "authdata=getAuthData()\n",
    "\n",
    "CONSUMER_KEY = authdata['CONSUMER_KEY']\n",
    "CONSUMER_SECRET = authdata['CONSUMER_SECRET']\n",
    "OAUTH_TOKEN = authdata['OAUTH_TOKEN']\n",
    "OAUTH_TOKEN_SECRET = authdata['OAUTH_TOKEN_SECRET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#getTweepyData('The Hunger Games',\"The Hunger Games.txt\")\n",
    "#getTweepyData('The Dark Knight Rises',\"The Dark Knight Rises.txt\")\n",
    "#getTweepyData('Django Unchained',\"Django Unchained.txt\")\n",
    "#getTweepyData('The Perks of Being a Wallflower',\"The Perks of Being a Wallflower.txt\")\n",
    "#getTweepyData('Moonrise Kingdom',\"Moonrise Kingdom.txt\")\n",
    "#getTweepyData('Pitch Perfect',\"Pitch Perfect.txt\")\n",
    "#getTweepyData('Silver Linings Playbook',\"Silver Linings Playbook.txt\")\n",
    "#getTweepyData('Skyfall',\"Skyfall.txt\")\n",
    "#getTweepyData('Looper',\"Looper.txt\")\n",
    "#getTweepyData('Magic Mike',\"Magic Mike.txt\")\n",
    "#getTweepyData('Argo',\"Argo.txt\")\n",
    "#getTweepyData('Flight',\"Flight.txt\")\n",
    "#getTweepyData('Lincoln',\"Lincoln.txt\")\n",
    "#getTweepyData('The Cabin in the Woods',\"The Cabin in the Woods.txt\")\n",
    "#getTweepyData('21 Jump Street',\"21 Jump Street.txt\")\n",
    "#getTweepyData('Life of Pi',\"Life of Pi.txt\")\n",
    "#getTweepyData('The Impossible',\"The Impossible.txt\")\n",
    "#getTweepyData('End of Watch',\"End of Watch.txt\")\n",
    "#getTweepyData('The Master',\"The Master.txt\")\n",
    "#getTweepyData('Seven Psychopaths',\"Seven Psychopaths.txt\")\n",
    "#getTweepyData('Brave',\"Brave.txt\")\n",
    "#getTweepyData('Chronicle',\"Chronicle.txt\")\n",
    "#getTweepyData('ParaNorman',\"ParaNorman.txt\")\n",
    "#getTweepyData('A Royal Affair',\"A Royal Affair.txt\")\n",
    "#getTweepyData('Amour',\"Amour.txt\")\n",
    "#getTweepyData('The Pirates! Band of Misfits',\"The Pirates Band of Misfits.txt\")\n",
    "#getTweepyData('Safety Not Guaranteed',\"Safety Not Guaranteed.txt\")\n",
    "#getTweepyData('Frankenweenie',\"Frankenweenie.txt\")\n",
    "#getTweepyData('Beasts of the Southern Wild',\"Beasts of the Southern Wild.txt\")\n",
    "#getTweepyData('Holy Motors',\"Holy Motors.txt\")\n",
    "#getTweepyData('Arbitrage',\"Arbitrage.txt\")\n",
    "#getTweepyData('The Sessions',\"The Sessions.txt\")\n",
    "#getTweepyData('Starlet',\"Starlet.txt\")\n",
    "#getTweepyData('Robot & Frank',\"Robot & Frank.txt\")\n",
    "#getTweepyData('Compliance',\"Compliance.txt\")\n",
    "#getTweepyData('Smashed',\"Smashed.txt\")\n",
    "#getTweepyData('Barbara',\"Barbara.txt\")\n",
    "#getTweepyData('Farewell, My Queen',\"Farewell My Queen.txt\")\n",
    "#getTweepyData('Middle of Nowhere',\"Middle of Nowhere.txt\")\n",
    "#getTweepyData('Keep the Lights On',\"Keep the Lights On.txt\")\n",
    "#getTweepyData('Tabu',\"Tabu.txt\")\n",
    "getTweepyData('Zero Dark Thirty',\"Zero Dark Thirty.txt\")\n",
    "getTweepyData('Les Miserables',\"Les Miserables.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "HungerGame = getScore('The Hunger Games.txt')\n",
    "DarkKnightRises = getScore('The Dark Knight Rises.txt')\n",
    "Django = getScore('Django Unchained.txt')\n",
    "Wallflower = getScore('The Perks of Being a Wallflower.txt')\n",
    "MoonriseKingdom = getScore('Moonrise Kingdom.txt')\n",
    "PitchPerfec = getScore('Pitch Perfect.txt')\n",
    "SilverLiningsPlaybook = getScore('Silver Linings Playbook.txt')\n",
    "Skyfall = getScore('Skyfall.txt')\n",
    "Looper = getScore('Looper.txt')\n",
    "MagicMike = getScore('Magic Mike.txt')\n",
    "Argo = getScore('Argo.txt')\n",
    "Flight = getScore('Flight.txt')\n",
    "Lincoln = getScore('Lincoln.txt')\n",
    "CabinintheWoods = getScore('The Cabin in the Woods.txt')\n",
    "JumpStreet21 = getScore('21 Jump Street.txt')\n",
    "LifeofPi = getScore('Life of Pi.txt')\n",
    "TheImpossible = getScore('The Impossible.txt')\n",
    "EndofWatch = getScore('End of Watch.txt')\n",
    "Master = getScore('The Master.txt')\n",
    "SevenPsychopaths = getScore('Seven Psychopaths.txt')\n",
    "Brave = getScore('Brave.txt')\n",
    "Chronicle = getScore('Chronicle.txt')\n",
    "ParaNorman = getScore('ParaNorman.txt')\n",
    "ARoyalAffair = getScore('A Royal Affair.txt')\n",
    "Amour = getScore('Amour.txt')\n",
    "PiratesBand = getScore('The Pirates Band of Misfits.txt')\n",
    "SafetyNotGuaranteed = getScore('Safety Not Guaranteed.txt')\n",
    "Frankenweenie = getScore('Frankenweenie.txt')\n",
    "SouthernWild = getScore('Beasts of the Southern Wild.txt')\n",
    "HolyMotors = getScore('Holy Motors.txt')\n",
    "Arbitrage = getScore('Arbitrage.txt')\n",
    "TheSessions = getScore('The Sessions.txt')\n",
    "Starlet = getScore('Starlet.txt')\n",
    "RobotFrank = getScore('Robot & Frank.txt')\n",
    "Compliance = getScore('Compliance.txt')\n",
    "Smashed = getScore('Smashed.txt')\n",
    "Barbara = getScore('Barbara.txt')\n",
    "FarewellMyQueen = getScore('Farewell My Queen.txt')\n",
    "MiddleofNowhere = getScore('Middle of Nowhere.txt')\n",
    "KeeptheLightsOn = getScore('Keep the Lights On.txt')\n",
    "Tabu = getScore('Tabu.txt')\n",
    "ZeroDarkThirty = getScore('Zero Dark Thirty.txt')\n",
    "LesMiserables = getScore('Les Miserables.txt')\n",
    "\n",
    "data = [HungerGame,DarkKnightRises,Django,Wallflower,MoonriseKingdom,PitchPerfec,SilverLiningsPlaybook,Skyfall,\\\n",
    "        Looper,MagicMike,Argo,Flight,Lincoln,CabinintheWoods,JumpStreet21,LifeofPi,TheImpossible,EndofWatch,Master,\\\n",
    "        SevenPsychopaths,Brave,Chronicle,ParaNorman,ARoyalAffair,Amour,PiratesBand,SafetyNotGuaranteed,\\\n",
    "        Frankenweenie,SouthernWild,HolyMotors,Arbitrage,TheSessions,Starlet,RobotFrank,Compliance,Smashed,Barbara,\\\n",
    "        FarewellMyQueen,MiddleofNowhere,KeeptheLightsOn,Tabu,ZeroDarkThirty,LesMiserables]\n",
    "\n",
    "MovieName =[\"The Hunger Games\",\"The Dark Knight Rises\",\"Django Unchained\",\"The Perks of Being a Wallflower\",\\\n",
    "            \"Moonrise Kingdom\",\"Pitch Perfect\",\"Silver Linings Playbook\",\"Skyfall\",\"Looper\",\"Magic Mike\",\"Argo\",\\\n",
    "            \"Flight\",\"Lincoln\",\"The Cabin in the Woods\",\"21 Jump Street\",\"Life of Pi\",\"The Impossible\",\\\n",
    "            \"End of Watch\",\"The Master\",\"Seven Psychopaths\",\"Brave\",\"Chronicle\",\"ParaNorman\",\"A Royal Affair\",\\\n",
    "            \"Amour\",\"The Pirates! Band of Misfits\",\"Safety Not Guaranteed\",\"Frankenweenie\",\\\n",
    "            \"Beasts of the Southern Wild\",\"Holy Motors\",\"Arbitrage\",\"The Sessions\",\"Starlet\",\"Robot & Frank\",\\\n",
    "            \"Compliance\",\"Smashed\",\"Barbara\",\"Farewell, My Queen\",\"Middle of Nowhere\",\"Keep the Lights On\",\"Tabu\",\\\n",
    "            \"Zero Dark Thirty\",\"Les Miserables\"]\n",
    "\n",
    "DF = pd.DataFrame({\"MovieName\":MovieName,\"SentimentScore\":data})\n",
    "\n",
    "DF.to_csv('2012all.csv')\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')  \n",
    "\n",
    "DF.plot(kind=\"bar\")\n",
    "plt.title(\"Sentiment Analysis of Movies in 2012\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis for Movies in 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#getTweepyData('American Hustle',\"AmericanHustle.txt\")\n",
    "#getTweepyData('Captain Phillips',\"CaptainPhillips.txt\")\n",
    "#getTweepyData('Dallas Buyers Club',\"DallasBuyersClub.txt\")\n",
    "#getTweepyData('Gravity',\"Gravity.txt\")\n",
    "#getTweepyData('Her',\"Her.txt\")\n",
    "#getTweepyData('Nebraska',\"Nebraska.txt\")\n",
    "#getTweepyData('Philomena',\"Philomena.txt\")\n",
    "#getTweepyData('The Wolf of Wall Street',\"TheWolfofWallStreet.txt\")\n",
    "\n",
    "#getTweepyData('The Conjuring','Conjuring.txt')\n",
    "#getTweepyData('Prisoners','Prisoners.txt')\n",
    "#getTweepyData('Star Trek Into Darkness','StarTrek.txt')\n",
    "#getTweepyData('12 Years a Slave','Slave.txt')\n",
    "#getTweepyData('Frozen','Frozen.txt')\n",
    "#getTweepyData('Rush','Rush.txt')\n",
    "#getTweepyData('Warm Bodies','Warm.txt')\n",
    "#getTweepyData('This is the End','End.txt')\n",
    "#getTweepyData('The Hunger Games: Catching Fire','HungerGame.txt')\n",
    "#getTweepyData(\"The World's End\",\"WorldEnd.txt\")\n",
    "\n",
    "#getTweepyData('Don Jon','Don.txt')\n",
    "#getTweepyData('The Spectacular Now','Spectaculat.txt')\n",
    "#getTweepyData('Inside Llewyn Davis','Davis.txt')\n",
    "#getTweepyData('Saving Mr.Banks','Banks.txt')\n",
    "#getTweepyData('Side Effects','SideEffects.txt')\n",
    "#getTweepyData('Blue Jasmine','Jasmine.txt')\n",
    "#getTweepyData('The Way Way Back','Back.txt')\n",
    "#getTweepyData('Short Term 12','Short.txt')\n",
    "#getTweepyData('Before Midnight','Midnight.txt')\n",
    "#getTweepyData('We Are What We Are','weare.txt')\n",
    "\n",
    "#getTweepyData('Fruitvale Station','Fruit.txt')\n",
    "#getTweepyData('Upstream Color','Upstream.txt')\n",
    "#getTweepyData('Drinking Buddies','Drinking.txt')\n",
    "#getTweepyData('All is Lost','Lost.txt')\n",
    "#getTweepyData('Enough Said','EnoughSaid.txt')\n",
    "#getTweepyData('Le passé','Le.txt')\n",
    "#getTweepyData('In a World','World.txt')\n",
    "#getTweepyData('Computer Chess','ComputerChess.txt')\n",
    "getTweepyData('The Selfish Giant','Giant.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "Hustle = getScore('AmericanHustle.txt')\n",
    "Captain = getScore('CaptainPhillips.txt')\n",
    "Club = getScore('DallasBuyersClub.txt')\n",
    "Gravity = getScore('Gravity.txt')\n",
    "Her = getScore('Her.txt')\n",
    "Nebraska = getScore('Nebraska.txt')\n",
    "Philomena = getScore('Philomena.txt')\n",
    "Street = getScore('TheWolfofWallStreet.txt')\n",
    "\n",
    "Conjuring = getScore('Conjuring.txt')\n",
    "Prisoners = getScore('Prisoners.txt')\n",
    "StarTrek = getScore('StarTrek.txt')\n",
    "Slave = getScore('Slave.txt')\n",
    "Frozen = getScore('Frozen.txt')\n",
    "Rush = getScore('Rush.txt')\n",
    "Warm = getScore('Warm.txt')\n",
    "End = getScore('End.txt')\n",
    "Hunger = getScore('HungerGame.txt')\n",
    "WorldEnd = getScore('WorldEnd.txt')\n",
    "\n",
    "Don = getScore('Don.txt')\n",
    "Spect = getScore('Spectaculat.txt')\n",
    "Davis = getScore('Davis.txt')\n",
    "Banks = getScore('Banks.txt')\n",
    "Side= getScore('SideEffects.txt')\n",
    "Jasmine = getScore('Jasmine.txt')\n",
    "Back = getScore('Back.txt')\n",
    "Short = getScore('Short.txt')\n",
    "Midnight = getScore('Midnight.txt')\n",
    "weare = getScore('weare.txt')\n",
    "\n",
    "Fruit = getScore('Fruit.txt')\n",
    "Upstream = getScore('Upstream.txt')\n",
    "Drinking = getScore('Drinking.txt')\n",
    "Lost = getScore('Lost.txt')\n",
    "EnoughSaid = getScore('EnoughSaid.txt')\n",
    "Le = getScore('Le.txt')\n",
    "World = getScore('World.txt')\n",
    "Chess = getScore('ComputerChess.txt')\n",
    "Giant = getScore('Giant.txt')\n",
    "\n",
    "data = [Hustle,Captain,Club,Gravity,Her,Nebraska,Philomena,Street,\\\n",
    "       Conjuring,Prisoners,StarTrek,Slave,Frozen,Rush,Warm,End,Hunger,WorldEnd,\\\n",
    "       Don,Spect,Davis,Banks,Side,Jasmine,Back,Short,Midnight,weare,\\\n",
    "       Fruit,Upstream,Drinking,Lost,EnoughSaid,Le,World,Chess,Giant]\n",
    "\n",
    "MovieName =['AmericanHustle','CaptainPhillips','DallasBuyersClub','Gravity','Her','Nebraska','Philomena','TheWolfofWallStreet',\\\n",
    "           'The Conjuring','Prisoners','Star Trek Into Darkness','12 Years a Slave','Frozen','Rush','Warm Bodies',\\\n",
    "           'This Is is the End','The Hunger Games: Catching Fire',\"The World's End\",\\\n",
    "           'Don Jon','The Spectacular Now','Inside Llewyn Davis','Saving Mr. Banks','Side Effects',\\\n",
    "           'Blue Jasmine','The Way Way Back','Short Term 12','Before Midnight','We Are What We Are',\\\n",
    "           'Fruitvale Station','Upstram Color','Drinking Buddies','All Is Lost','Enough Said','Le passé',\\\n",
    "           'In a World...','Computer Chess','The Selfish Giant']\n",
    "\n",
    "DF = pd.DataFrame({\"MovieName\":MovieName,\"SentimentScore\":data})\n",
    "\n",
    "DF.to_csv('2014candidate.csv')\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')  \n",
    "\n",
    "DF.plot(kind=\"bar\")\n",
    "plt.title(\"Sentiment Analysis of Movies in 2013\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Sentiment Analysis for 38 Movies in 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#getTweepyData('Guardians of the Galaxy',\"Guardians of the Galaxy.txt\")\n",
    "#getTweepyData('Gone Girl',\"Gone Girl.txt\")\n",
    "#getTweepyData('The Babadook',\"The Babadook.txt\")\n",
    "#getTweepyData('John Wick',\"John Wick.txt\")\n",
    "#getTweepyData('X-Men:Days of Future Past',\"X-MenDaysofFuturePast.txt\")\n",
    "#getTweepyData('Captain America:The Winter Soldier',\"CaptainAmericaTheWinterSoldier.txt\")\n",
    "#getTweepyData('Nightcrawler',\"Nightcrawler.txt\")\n",
    "#getTweepyData('The Guest',\"The Guest.txt\")\n",
    "#getTweepyData('Big Hero 6',\"Big Hero 6.txt\")\n",
    "#getTweepyData('A Girl Walks Home Alone at Night',\"A Girl Walks Home Alone at Night.txt\")\n",
    "#getTweepyData('Chef',\"Chef.txt\")\n",
    "#getTweepyData('22 Jump Street',\"22 Jump Street.txt\")\n",
    "#getTweepyData('Wild',\"Wild.txt\")\n",
    "#getTweepyData('How to Train Your Dragon 2',\"How to Train Your Dragon 2.txt\")\n",
    "#getTweepyData('The Drop',\"The Drop.txt\")\n",
    "#getTweepyData('Foxcatcher',\"Foxcatcher.txt\")\n",
    "#getTweepyData('A Most Wanted Man',\"A Most Wanted Man.txt\")\n",
    "#getTweepyData('Pride',\"Pride.txt\")\n",
    "#getTweepyData('Frank',\"Frank.txt\")\n",
    "#getTweepyData('Calvary',\"Calvary.txt\")\n",
    "#getTweepyData('Top Five',\"Top Five.txt\")\n",
    "#getTweepyData('Cold in July',\"Cold in July.txt\")\n",
    "#getTweepyData('Leviathan',\"Leviathan.txt\")\n",
    "#getTweepyData('The Good Lie',\"The Good Lie.txt\")\n",
    "#getTweepyData('Mr Turner',\"Mr Turner.txt\")\n",
    "#getTweepyData('The Skeleton Twins',\"The Skeleton Twins.txt\")\n",
    "#getTweepyData('Dear White People',\"Dear White People.txt\")\n",
    "#getTweepyData('Obvious Child',\"Obvious Child.txt\")\n",
    "getTweepyData('Love Is Strange',\"Love Is Strange-test.txt\")\n",
    "getTweepyData('Gloria',\"Gloria-test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "AS = getScore('AmericanSniper.txt')\n",
    "Boyhood = getScore('Boyhood.txt')\n",
    "TGBH = getScore('TheGrandBudapestHotel.txt')\n",
    "TIG = getScore('TheImitationGame.txt')\n",
    "Selma = getScore('Selma.txt')\n",
    "Birdman = getScore('Birdman.txt')\n",
    "Theory = getScore('TheTheoryOfEverything.txt')\n",
    "Whiplash = getScore('Whiplash.txt')\n",
    "\n",
    "Galaxy = getScore('Guardians of the Galaxy.txt')\n",
    "GoneGirl = getScore('Gone Girl.txt')\n",
    "Babadook = getScore('The Babadook.txt')\n",
    "JohnWick = getScore('John Wick.txt')\n",
    "XMen = getScore('X-MenDaysofFuturePast.txt')\n",
    "CaptainAmerica = getScore('CaptainAmericaTheWinterSoldier.txt')\n",
    "Nightcrawler = getScore('Nightcrawler.txt')\n",
    "TheGuest = getScore('The Guest.txt')\n",
    "BigHero6 = getScore('Big Hero 6.txt')\n",
    "AGirlWalksHomeAlone= getScore('A Girl Walks Home Alone at Night.txt')\n",
    "Chef = getScore('Chef.txt')\n",
    "JumpStreet = getScore('22 Jump Street.txt')\n",
    "Wild = getScore('Wild.txt')\n",
    "Dragon2 = getScore('How to Train Your Dragon 2.txt')\n",
    "TheDrop = getScore('The Drop.txt')\n",
    "Foxcatcher = getScore('Foxcatcher.txt')\n",
    "AMostWantedMan = getScore('A Most Wanted Man.txt')\n",
    "Pride = getScore('Pride.txt')\n",
    "Frank = getScore('Frank.txt')\n",
    "Calvary = getScore('Calvary.txt')\n",
    "TopFive = getScore('Top Five.txt')\n",
    "ColdinJuly = getScore('Cold in July.txt')\n",
    "Leviathan = getScore('Leviathan.txt')\n",
    "TheGoodLie = getScore('The Good Lie.txt')\n",
    "MrTurner = getScore('Mr Turner.txt')\n",
    "TheSkeletonTwins = getScore('The Skeleton Twins.txt')\n",
    "DearWhitePeople = getScore('Dear White People.txt')\n",
    "ObviousChild = getScore('Obvious Child.txt')\n",
    "LoveIsStrange = getScore('Love Is Strange.txt')\n",
    "Gloria = getScore('Gloria.txt')\n",
    "\n",
    "\n",
    "\n",
    "data = [AS,Boyhood,TGBH,TIG,Selma,Birdman,Theory,Whiplash,\\\n",
    "        Galaxy,GoneGirl,Babadook,JohnWick,XMen,CaptainAmerica,Nightcrawler,TheGuest,BigHero6,AGirlWalksHomeAlone,Chef,JumpStreet,\\\n",
    "        Wild,Dragon2,TheDrop,Foxcatcher,AMostWantedMan,Pride,Frank,Calvary,TopFive,ColdinJuly,Leviathan,TheGoodLie,\\\n",
    "        MrTurner,TheSkeletonTwins,DearWhitePeople,ObviousChild,LoveIsStrange,Gloria]\n",
    "MovieName =['American Sniper','Boyhood','The Grand Budapest Hotel','The Imitation Game','Selma','Birdman',\\\n",
    "            'The Theory of Everything','Whiplash',\\\n",
    "            'Guardians of the Galaxy','Gone Girl','The Babadook','John Wick','X-Men:Days of Future Past','Captain America:The Winter Soldier',\\\n",
    "            'Nightcrawler','The Guest','Big Hero 6','A Girl Walks Home Alone at Night','Chef','22 Jump Street',\\\n",
    "            'Wild','How to Train Your Dragon 2','The Drop','Foxcatcher','A Most Wanted Man','Pride','Frank',\\\n",
    "            'Calvary','Top Five','Cold in July','Leviathan','The Good Lie','Mr. Turner','The Skeleton Twins',\\\n",
    "            'Dear White People','Obvious Child','Love Is Strange','Gloria']\n",
    "DF = pd.DataFrame({\"MovieName\":MovieName,\"SentimentScore\":data})\n",
    "\n",
    "DF.to_csv('2014all.csv')\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')  \n",
    "\n",
    "DF.plot(kind=\"bar\")\n",
    "plt.title(\"Sentiment Analysis of Movies in 2014\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis for Movies in 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#getTweepyData('The Big Short',\"TheBigShort.txt\")\n",
    "#getTweepyData('Bridge of Spies',\"BridgeOfSpies.txt\")\n",
    "#getTweepyData('Brooklyn',\"Brooklyn.txt\")\n",
    "#getTweepyData('Mad Max: Fury Road',\"MadMaxFuryRoad.txt\")\n",
    "#getTweepyData('The Martian',\"TheMartian.txt\")\n",
    "#getTweepyData('The Revenant',\"TheRevenant.txt\")\n",
    "#getTweepyData('Room',\"Room.txt\")\n",
    "#getTweepyData('Spotlight',\"Spotlight.txt\")\n",
    "\n",
    "#getTweepyData('Sicario','Sicario.txt')\n",
    "#getTweepyData('Ex Machina','ExMachina.txt')\n",
    "#getTweepyData('Inside Out','InsideOut.txt')\n",
    "#getTweepyData('Ant-Man','AntMan.txt')\n",
    "#getTweepyData('Straight Outta Compton','StraightOuttaCompton.txt')\n",
    "#getTweepyData('Carol','Carol.txt')\n",
    "#getTweepyData('Steve Jobs','SteveJobs.txt')\n",
    "#getTweepyData('Trainwreck','Trainwreck.txt')\n",
    "#getTweepyData('The Gift','TheGift.txt')\n",
    "#getTweepyData('Spy','Spy.txt')\n",
    "#getTweepyData('Creed','Creed.txt')\n",
    "#getTweepyData('Bone Tomahawk','BoneTomahawk.txt')\n",
    "\n",
    "#getTweepyData('Dope','Dope.txt')\n",
    "#getTweepyData('The Walk','The Walk.txt')\n",
    "#getTweepyData('Anomalisa','Anomalisa.txt')\n",
    "#getTweepyData('Beasts of No Nation','Beasts.txt')\n",
    "#getTweepyData('Mr.Holmes','Holmes.txt')\n",
    "#getTweepyData('45 Years','45Years.txt')\n",
    "#getTweepyData('We Are Still Here','Still.txt')\n",
    "#getTweepyData('The Peanuts Movie','Peanuts.txt')\n",
    "\n",
    "#getTweepyData('Mustang','Mustang.txt')\n",
    "#getTweepyData('Slow West','Slow West.txt')\n",
    "#getTweepyData('Mississippi Grind','Mississippi.txt')\n",
    "#getTweepyData('Tangerine','Tangerine.txt')\n",
    "#getTweepyData('Grandma','Grandma.txt')\n",
    "#getTweepyData('Shaun the Sheep Movie','Shaun.txt')\n",
    "#getTweepyData('James White','JamesWhite.txt')\n",
    "#getTweepyData(\"I'll See You in My Dreams\",\"Dreams.txt\")\n",
    "getTweepyData(\"The Forbidden Room\",\"Forbidden.txt\")\n",
    "getTweepyData(\"Queen of Earth\",\"Earth.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "TBS = getScore('TheBigShort.txt')\n",
    "BoS = getScore('BridgeOfSpies.txt')\n",
    "Brooklyn = getScore('Brooklyn.txt')\n",
    "MadMax = getScore('MadMaxFuryRoad.txt')\n",
    "Martian = getScore('TheMartian.txt')\n",
    "Revenant = getScore('TheRevenant.txt')\n",
    "Room = getScore('Room.txt')\n",
    "Spotlight = getScore('Spotlight.txt')\n",
    "\n",
    "Sicario = getScore('Sicario.txt')\n",
    "Machina = getScore('ExMachina.txt')\n",
    "Inside = getScore('InsideOut.txt')\n",
    "AntMan = getScore('AntMan.txt')\n",
    "Straight = getScore('StraightOuttaCompton.txt')\n",
    "Carol = getScore('Carol.txt')\n",
    "SteveJobs = getScore('SteveJobs.txt')\n",
    "Train = getScore('Trainwreck.txt')\n",
    "Gift = getScore('TheGift.txt')\n",
    "Spy = getScore('Spy.txt')\n",
    "Creed = getScore('Creed.txt')\n",
    "Bone = getScore('BoneTomahawk.txt')\n",
    "\n",
    "Dope = getScore('Dope.txt')\n",
    "Walk = getScore('The Walk.txt')\n",
    "Anomalisa = getScore('Anomalisa.txt')\n",
    "Beasts = getScore('Beasts.txt')\n",
    "Holmes = getScore('Holmes.txt')\n",
    "Years = getScore('45Years.txt')\n",
    "Still = getScore('Still.txt')\n",
    "Peanuts = getScore('Peanuts.txt')\n",
    "\n",
    "Mustang = getScore('Mustang.txt')\n",
    "West = getScore('Slow West.txt')\n",
    "Missi = getScore('Mississippi.txt')\n",
    "Tangerine = getScore('Tangerine.txt')\n",
    "Grandma = getScore('Grandma.txt')\n",
    "Shaun = getScore('Shaun.txt')\n",
    "James = getScore('JamesWhite.txt')\n",
    "Dreams = getScore('Dreams.txt')\n",
    "Forbidden = getScore('Forbidden.txt')\n",
    "Earth = getScore('Earth.txt')\n",
    "\n",
    "data = [TBS,BoS,Brooklyn,MadMax,Martian,Revenant,Room,Spotlight,\\\n",
    "        Sicario,Machina,Inside,AntMan,Straight,Carol,SteveJobs,\\\n",
    "        Train,Gift,Spy,Creed,Bone,\\\n",
    "        Dope,Walk,Anomalisa,Beasts,Holmes,Years,Still,Peanuts,\\\n",
    "        Mustang,West,Missi,Tangerine,Grandma,\\\n",
    "        Shaun,James,Dreams,Forbidden,Earth]\n",
    "print(data)\n",
    "print(len(data))\n",
    "MovieName =['The Big Short','Bridge Of Spies','Brooklyn','Mad Max: Fury Road','The Martian','The Revenant','Room','Spotlight',\\\n",
    "           'Sicario','Ex Machina','Inside Out','Ant-Man','Straight Outta Compton','Carol','Steve Jobs',\\\n",
    "            'Trainwreck','The Gift','Spy','Creed','Bone Tomahawk',\\\n",
    "           'Dope','The Walk','Anomalisa','Beasts of No Nation','Mr.Holmes',\\\n",
    "           '45 Years','We Are Still Here','The Peanuts Movie',\\\n",
    "           'Mustang','Slow West','Mississippi Grind','Tangerine','Grandma',\\\n",
    "           'Shaun the Sheep Movie','James White',\"I'll See You in My Dreams\",'The Forbidden Room','Queen of Earth']\n",
    "print(MovieName)\n",
    "print(len(MovieName))\n",
    "DF = pd.DataFrame({\"MovieName\":MovieName,\"SentimentScore\":data})\n",
    "DF.to_csv('2016candidate.csv')\n",
    "\n",
    "print(DF)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')  \n",
    "\n",
    "DF.plot(kind=\"bar\")\n",
    "plt.title(\"Sentiment Analysis of Movies in 2015\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis for 41 Movies in 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#getTweepyData('10 Cloverfield Lane',\"10 Cloverfield Lane.txt\")\n",
    "#getTweepyData('Aquarius',\"Aquarius.txt\")\n",
    "#getTweepyData('Arrival',\"Arrival.txt\")\n",
    "#getTweepyData('Barbershop: The Next Cut',\"BarbershopTheNextCut.txt\")\n",
    "#getTweepyData('Blood Father',\"Blood Father.txt\")\n",
    "#getTweepyData('Captain America:Civil War',\"CaptainAmericaCivilWar.txt\")\n",
    "#getTweepyData('Certain Women',\"Certain Women.txt\")\n",
    "#getTweepyData('Deadpool',\"Deadpool.txt\")\n",
    "#getTweepyData('Deepwater Horizon',\"Deepwater Horizon.txt\")\n",
    "#getTweepyData('Doctor Strange',\"Doctor Strange.txt\")\n",
    "#getTweepyData(\"Don't Breathe\",\"Dont Breathe.txt\")\n",
    "#getTweepyData(\"Don't Think Twice\",\"Dont Think Twice.txt\")\n",
    "#getTweepyData('Elle',\"Elle.txt\")\n",
    "#getTweepyData('Everybody Wants Some',\"Everybody Wants Some.txt\")\n",
    "#getTweepyData('Finding Dory',\"Finding Dory.txt\")\n",
    "#getTweepyData('Florence Foster Jenkins',\"Florence Foster Jenkins.txt\")\n",
    "#getTweepyData('Hacksaw Ridge',\"Hacksaw Ridge.txt\")\n",
    "#getTweepyData('Hail, Caesar',\"HailCaesar.txt\")\n",
    "#getTweepyData('Hell or High Water',\"Hell or High Water.txt\")\n",
    "#getTweepyData('Hunt for the Wilderpeople',\"Hunt for the Wilderpeople.txt\")\n",
    "#getTweepyData('I, Daniel Blake',\"I Daniel Blake.txt\")\n",
    "#getTweepyData('Kubo and the Two Strings',\"Kubo and the Two Strings.txt\")\n",
    "#getTweepyData('Kung Fu Panda 3',\"Kung Fu Panda 3.txt\")\n",
    "#getTweepyData('La La Land',\"La La Land.txt\")\n",
    "#getTweepyData('Little Men',\"Little Men.txt\")\n",
    "#getTweepyData('Love & Friendship',\"LoveFriendship.txt\")\n",
    "#getTweepyData('Loving',\"Loving.txt\")\n",
    "#getTweepyData('Manchester by the Sea',\"Manchester by the Sea.txt\")\n",
    "#getTweepyData('Midnight Special',\"Midnight Special.txt\")\n",
    "#getTweepyData('Moonlight',\"Moonlight.txt\")\n",
    "#getTweepyData('Morris from America',\"Morris from America.txt\")\n",
    "#getTweepyData(\"Pete's Dragon\",\"PetesDragon.txt\")\n",
    "#getTweepyData('Queen of Katwe',\"Queen of Katwe.txt\")\n",
    "#getTweepyData('Sing Street',\"Sing Street.txt\")\n",
    "#getTweepyData('Star Trek Beyond',\"Star Trek Beyond.txt\")\n",
    "#getTweepyData('Sully',\"Sully.txt\")\n",
    "#getTweepyData('The Innocents',\"The Innocents.txt\")\n",
    "#getTweepyData('The Jungle Book',\"The Jungle Book.txt\")\n",
    "#getTweepyData('The Nice Guys',\"The Nice Guys.txt\")\n",
    "#getTweepyData('The Wailing',\"The Wailing.txt\")\n",
    "getTweepyData('Zootopia',\"Zootopia.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "Cloverfield = getScore('10 Cloverfield Lane.txt')\n",
    "Aquarius = getScore('Aquarius.txt')\n",
    "Arrival = getScore('Arrival.txt')\n",
    "Barbershop = getScore('BarbershopTheNextCut.txt')\n",
    "BloodFather = getScore('Blood Father.txt')\n",
    "CaptainAmericaCivilWar = getScore('CaptainAmericaCivilWar.txt')\n",
    "CertainWomen = getScore('Certain Women.txt')\n",
    "Deadpool = getScore('Deadpool.txt')\n",
    "DeepwaterHorizon = getScore('Deepwater Horizon.txt')\n",
    "DoctorStrange = getScore('Doctor Strange.txt')\n",
    "DontBreathe = getScore('Dont Breathe.txt')\n",
    "DontThinkTwice = getScore('Dont Think Twice.txt')\n",
    "Elle = getScore('Elle.txt')\n",
    "Everybody = getScore('Everybody Wants Some.txt')\n",
    "FindingDory = getScore('Finding Dory.txt')\n",
    "FlorenceFosterJenkins = getScore('Florence Foster Jenkins.txt')\n",
    "HacksawRidge = getScore('Hacksaw Ridge.txt')\n",
    "HailCaesar = getScore('HailCaesar.txt')\n",
    "HighWater = getScore('Hell or High Water.txt')\n",
    "Wilderpeople = getScore('Hunt for the Wilderpeople.txt')\n",
    "IDanielBlake = getScore('I Daniel Blake.txt')\n",
    "KuboTwoStrings = getScore('Kubo and the Two Strings.txt')\n",
    "KungFuPanda3 = getScore('Kung Fu Panda 3.txt')\n",
    "LaLaLand = getScore('La La Land.txt')\n",
    "LittleMen = getScore('Little Men.txt')\n",
    "LoveFriendship = getScore('LoveFriendship.txt')\n",
    "Loving = getScore('Loving.txt')\n",
    "Manchester = getScore('Manchester by the Sea.txt')\n",
    "MidnightSpecial = getScore('Midnight Special.txt')\n",
    "Moonlight = getScore('Moonlight.txt')\n",
    "MorrisfromAmerica = getScore('Morris from America.txt')\n",
    "PetesDragon = getScore('PetesDragon.txt')\n",
    "QueenofKatwe = getScore('Queen of Katwe.txt')\n",
    "SingStreet = getScore('Sing Street.txt')\n",
    "StarTrekBeyond = getScore('Star Trek Beyond.txt')\n",
    "Sully = getScore('Sully.txt')\n",
    "TheInnocents = getScore('The Innocents.txt')\n",
    "TheJungleBook = getScore('The Jungle Book.txt')\n",
    "TheNiceGuys = getScore('The Nice Guys.txt')\n",
    "TheWailing = getScore('The Wailing.txt')\n",
    "Zootopia = getScore('Zootopia.txt')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = [Cloverfield,Aquarius,Arrival,Barbershop,BloodFather,CaptainAmericaCivilWar,CertainWomen,Deadpool,DeepwaterHorizon,\\\n",
    "       DoctorStrange,DontBreathe,DontThinkTwice,Elle,Everybody,FindingDory,FlorenceFosterJenkins,HacksawRidge,HailCaesar,HighWater,\\\n",
    "       Wilderpeople,IDanielBlake,KuboTwoStrings,KungFuPanda3,LaLaLand,LittleMen,LoveFriendship,Loving,Manchester,MidnightSpecial,\\\n",
    "       Moonlight,MorrisfromAmerica,PetesDragon,QueenofKatwe,SingStreet,StarTrekBeyond,Sully,TheInnocents,TheJungleBook,\\\n",
    "       TheNiceGuys,TheWailing,Zootopia]\n",
    "MovieName =['10 Cloverfield Lane','Aquarius','Arrival','Barbershop: The Next Cut','Blood Father','Captain America: Civil War',\\\n",
    "           'Certain Women','Deadpool','Deepwater Horizon','Doctor Strange',\"Don't Breathe\",\"Don't Think Twice\",'Elle',\\\n",
    "           'Everybody Wants Some','Finding Dory','Florence Foster Jenkins','Hacksaw Ridge','Hail, Caesar','Hell or High Water',\\\n",
    "           'Hunt for the Wilderpeople','I, Daniel Blake','Kubo and the Two Strings','Kung Fu Panda 3','La La Land','Little Men',\\\n",
    "           'Love & Friendship','Loving','Manchester by the Sea','Midnight Special','Moonlight','Morris from America',\"Pete's Dragon\",\\\n",
    "           'Queen of Katwe','Sing Street','Star Trek Beyond','Sully','The Innocents','The Jungle Book','The Nice Guys',\\\n",
    "           'The Wailing','Zootopia']\n",
    "DF = pd.DataFrame({\"MovieName\":MovieName,\"SentimentScore\":data})\n",
    "\n",
    "DF.to_csv('2016testdata.csv')\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')  \n",
    "\n",
    "DF.plot(kind=\"bar\")\n",
    "plt.title(\"Sentiment Analysis of Movies in 2016\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMDB Web Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import pandas as pd\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrape(url,filename):\n",
    "    moviename=[]\n",
    "    rating=[]\n",
    "    movielist=[]\n",
    "    for i in range(1,21,1):\n",
    "        url1=url+str(i)\n",
    "        request=urllib.request.Request(url1)\n",
    "        response=urllib.request.urlopen(request)\n",
    "        data=response.read()\n",
    "        response.close()\n",
    "    \n",
    "        soup=bs(data,\"html.parser\")\n",
    "        a=soup.findAll(\"div\",{\"class\": \"lister-item mode-advanced\"})\n",
    "    \n",
    "        for value in a:\n",
    "            #print (value)\n",
    "            b=value.find(\"h3\",{\"class\": \"lister-item-header\"})\n",
    "            movie=b.find(\"a\").text.strip()\n",
    "            moviename.append(movie)\n",
    "       \n",
    "        for value in a:\n",
    "            c=value.find(\"div\",{\"class\":\"inline-block ratings-imdb-rating\"})\n",
    "            try:\n",
    "                rat=c.find(\"strong\").text.strip()\n",
    "           \n",
    "            except:\n",
    "                rat=0\n",
    "            rating.append(rat)\n",
    "    \n",
    "    movielist=pd.DataFrame({\"Movie Name\": moviename,'Rating':rating},columns=('Movie Name','Rating'))\n",
    "    \n",
    "    #Writing the output to a CSV file\n",
    "    movielist.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping IMDB data for the year 2016\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scrape(\"http://www.imdb.com/search/title?year=2016,2016&title_type=feature&sort=moviemeter,asc&page=\",\"imdb_2016.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping IMDB data for the year 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scrape(\"http://www.imdb.com/search/title?year=2015,2015&title_type=feature&sort=moviemeter,asc&page=\",\"imdb_2015.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping IMDB data for the year 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scrape(\"http://www.imdb.com/search/title?year=2014,2014&title_type=feature&sort=moviemeter,asc&page=\",\"imdb_2014.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping IMDB data for the year 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scrape(\"http://www.imdb.com/search/title?year=2013,2013&title_type=feature&sort=moviemeter,asc&page=\",\"imdb_2013.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping IMDB data for the year 2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scrape(\"http://www.imdb.com/search/title?year=2012,2012&title_type=feature&sort=moviemeter,asc&page=\",\"imdb_2012.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Scraping for Rotten Tomatoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def step1(url,fileName):\n",
    "    time.sleep(3)\n",
    "    myList = []\n",
    "    scoreList = []\n",
    "    nameList = []\n",
    "    \n",
    "    r = requests.get(url)\n",
    "    data = r.text\n",
    "    soup = bs(data, \"html.parser\")\n",
    "    scores = soup.findAll('span',{'class':'tMeterScore'})\n",
    "    for score in scores:\n",
    "        s = score.getText().strip().split('%')[0]\n",
    "        scoreList.append(s)\n",
    "    names = soup.findAll('a',{'class':'unstyled articleLink'})\n",
    "    for name in names:\n",
    "        n = name.getText().strip().split('(')[0]\n",
    "        nameList.append(n)\n",
    "    \n",
    "    length = len(scoreList)\n",
    "    for i in range(0,length-20):\n",
    "        print(nameList[i+44])\n",
    "        print(scoreList[i])\n",
    "        combine=[nameList[i+44], scoreList[i]]\n",
    "        myList.append(combine)\n",
    "        \n",
    "    headings = ['Name', 'Rating']\n",
    "    df2 = pd.DataFrame(myList, columns=headings)\n",
    "    df2.to_csv(fileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping 2016 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "step1(\"https://www.rottentomatoes.com/top/bestofrt/?year=2016\",\"rotten_2016.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping 2015 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "step1(\"https://www.rottentomatoes.com/top/bestofrt/?year=2015\",\"rotten_2015.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping 2014 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "step1(\"https://www.rottentomatoes.com/top/bestofrt/?year=2014\",\"rotten_2014.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping 2013 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "step1(\"https://www.rottentomatoes.com/top/bestofrt/?year=2013\",\"rotten_2013.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping 2012 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "step1(\"https://www.rottentomatoes.com/top/bestofrt/?year=2012\",\"rotten_2012.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL Querries to get data organized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!createdb -U dbuser prog_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%sql postgresql://dbuser@localhost:5432/prog_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TABLE IF EXISTS imdb_2015;\n",
    "\n",
    "CREATE TABLE imdb_2015(\n",
    "id SERIAL,\n",
    "movie_name VARCHAR(100),\n",
    "rating NUMERIC\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "COPY imdb_2015 FROM '/home/rithvik/prog/finalproj/imdb_2015.csv'\n",
    "CSV\n",
    "HEADER\n",
    "QUOTE '\"'\n",
    "DELIMITER ',';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT * FROM imdb_2015\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TABLE IF EXISTS rotten_2015;\n",
    "\n",
    "CREATE TABLE rotten_2015(\n",
    "id SERIAL,\n",
    "movie_name VARCHAR(100),\n",
    "rating NUMERIC\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "COPY rotten_2015 FROM '/home/rithvik/prog/finalproj/rotten_2015.csv'\n",
    "CSV\n",
    "HEADER\n",
    "QUOTE '\"'\n",
    "DELIMITER ',';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT * from rotten_2015\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TABLE IF EXISTS imdb_2014;\n",
    "\n",
    "CREATE TABLE imdb_2014(\n",
    "id SERIAL,\n",
    "movie_name VARCHAR(100),\n",
    "rating NUMERIC\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "COPY imdb_2014 FROM '/home/rithvik/prog/finalproj/imdb_2014.csv'\n",
    "CSV\n",
    "HEADER\n",
    "QUOTE '\"'\n",
    "DELIMITER ',';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "select * from imdb_2014\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TABLE IF EXISTS rotten_2014;\n",
    "\n",
    "CREATE TABLE rotten_2014(\n",
    "id SERIAL,\n",
    "movie_name VARCHAR(100),\n",
    "rating NUMERIC\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "COPY rotten_2014 FROM '/home/rithvik/prog/finalproj/rotten_2014.csv'\n",
    "CSV\n",
    "HEADER\n",
    "QUOTE '\"'\n",
    "DELIMITER ',';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql \n",
    "SELECT * from rotten_2014\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TABLE IF EXISTS imdb_2013;\n",
    "\n",
    "CREATE TABLE imdb_2013(\n",
    "id SERIAL,\n",
    "movie_name VARCHAR(100),\n",
    "rating NUMERIC\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "COPY imdb_2013 FROM '/home/rithvik/prog/finalproj/imdb_2013.csv'\n",
    "CSV\n",
    "HEADER\n",
    "QUOTE '\"'\n",
    "DELIMITER ',';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TABLE IF EXISTS rotten_2013;\n",
    "\n",
    "CREATE TABLE rotten_2013(\n",
    "id SERIAL,\n",
    "movie_name VARCHAR(100),\n",
    "rating NUMERIC\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "COPY rotten_2013 FROM '/home/rithvik/prog/finalproj/rotten_2013.csv'\n",
    "CSV\n",
    "HEADER\n",
    "QUOTE '\"'\n",
    "DELIMITER ',';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TABLE IF EXISTS imdb_2012;\n",
    "\n",
    "CREATE TABLE imdb_2012(\n",
    "id SERIAL,\n",
    "movie_name VARCHAR(100),\n",
    "rating NUMERIC\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "COPY imdb_2012 FROM '/home/rithvik/prog/finalproj/imdb_2012.csv'\n",
    "CSV\n",
    "HEADER\n",
    "QUOTE '\"'\n",
    "DELIMITER ',';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TABLE IF EXISTS rotten_2012;\n",
    "\n",
    "CREATE TABLE rotten_2012(\n",
    "id SERIAL,\n",
    "movie_name VARCHAR(100),\n",
    "rating NUMERIC\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "COPY rotten_2012 FROM '/home/rithvik/prog/finalproj/rotten_2012.csv'\n",
    "CSV\n",
    "HEADER\n",
    "QUOTE '\"'\n",
    "DELIMITER ',';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT i.movie_name,i.rating AS \"IMDB Rating\",r.rating AS \"Rotten Tomatoes Rating\",cast((((i.rating*10)+r.rating)/2) as Integer) AS \"Average rating\"\n",
    "FROM imdb_2015 i JOIN rotten_2015 r \n",
    "ON TRIM(i.movie_name)=TRIM(r.movie_name);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT i.movie_name,i.rating AS \"IMDB Rating\",r.rating AS \"Rotten Tomatoes Rating\",cast((((i.rating*10)+r.rating)/2) as Integer) AS \"Average rating\"\n",
    "FROM imdb_2014 i JOIN rotten_2014 r \n",
    "ON TRIM(i.movie_name)=TRIM(r.movie_name);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT i.movie_name,i.rating AS \"IMDB Rating\",r.rating AS \"Rotten Tomatoes Rating\",cast((((i.rating*10)+r.rating)/2) as Integer) AS \"Average rating\"\n",
    "FROM imdb_2013 i JOIN rotten_2013 r \n",
    "ON TRIM(i.movie_name)=TRIM(r.movie_name);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT i.movie_name,i.rating AS \"IMDB Rating\",r.rating AS \"Rotten Tomatoes Rating\",cast((((i.rating*10)+r.rating)/2) as Integer) AS \"Average rating\"\n",
    "FROM imdb_2012 i JOIN rotten_2012 r \n",
    "ON TRIM(i.movie_name)=TRIM(r.movie_name);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql \n",
    "\n",
    "COPY (SELECT i.movie_name,i.rating AS IMDB_Rating,r.rating AS Rotten_Tomatoes_Rating,cast((((i.rating*10)+r.rating)/2) as Integer) AS Average_rating\n",
    "FROM imdb_2012 i JOIN rotten_2012 r \n",
    "ON TRIM(i.movie_name)=TRIM(r.movie_name)) TO '/home/rithvik/prog/finalproj/2012 avg ratings.csv' CSV HEADER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are combining the average rating tables for all the years into a single file and writing it into a file named agg_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "COPY (\n",
    "SELECT i.movie_name,i.rating AS IMDB_Rating,r.rating AS Rotten_Tomatoes_Rating,cast((((i.rating*10)+r.rating)/2) as Integer) AS Average_rating\n",
    "FROM imdb_2014 i JOIN rotten_2014 r \n",
    "ON TRIM(i.movie_name)=TRIM(r.movie_name)\n",
    "UNION\n",
    "SELECT i.movie_name,i.rating AS IMDB_Rating,r.rating AS Rotten_Tomatoes_Rating,cast((((i.rating*10)+r.rating)/2) as Integer) AS Average_rating\n",
    "FROM imdb_2013 i JOIN rotten_2013 r \n",
    "ON TRIM(i.movie_name)=TRIM(r.movie_name)\n",
    "UNION\n",
    "SELECT i.movie_name,i.rating AS IMDB_Rating,r.rating AS Rotten_Tomatoes_Rating,cast((((i.rating*10)+r.rating)/2) as Integer) AS Average_rating\n",
    "FROM imdb_2012 i JOIN rotten_2012 r \n",
    "ON TRIM(i.movie_name)=TRIM(r.movie_name)) TO '/home/rithvik/prog/finalproj/agg_data.csv' CSV HEADER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are also creating a SQL table to store the average rating values of the top movies of all the years "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS avg_ratings;\n",
    "CREATE TABLE avg_ratings as\n",
    "SELECT i.movie_name,i.rating AS IMDB_Rating,r.rating AS Rotten_Tomatoes_Rating,cast((((i.rating*10)+r.rating)/2) as Integer) AS Average_rating\n",
    "FROM imdb_2014 i JOIN rotten_2014 r \n",
    "ON TRIM(i.movie_name)=TRIM(r.movie_name)\n",
    "UNION\n",
    "SELECT i.movie_name,i.rating AS IMDB_Rating,r.rating AS Rotten_Tomatoes_Rating,cast((((i.rating*10)+r.rating)/2) as Integer) AS Average_rating\n",
    "FROM imdb_2013 i JOIN rotten_2013 r \n",
    "ON TRIM(i.movie_name)=TRIM(r.movie_name)\n",
    "UNION\n",
    "SELECT i.movie_name,i.rating AS IMDB_Rating,r.rating AS Rotten_Tomatoes_Rating,cast((((i.rating*10)+r.rating)/2) as Integer) AS Average_rating\n",
    "FROM imdb_2012 i JOIN rotten_2012 r \n",
    "ON TRIM(i.movie_name)=TRIM(r.movie_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * from avg_ratings;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now importing the kaggle dataset to join the imported dataset with the avg_ratings table to find the budget, gross and duration of the movies.This final dataset is used for modelling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TABLE IF EXISTS kaggle_data;\n",
    "CREATE TABLE kaggle_data( \n",
    "duration NUMERIC,\n",
    "gross NUMERIC,\n",
    "movie_title VARCHAR(200),\n",
    "budget NUMERIC,\n",
    "facebook_likes NUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "COPY kaggle_data FROM '/home/rithvik/prog/finalproj/kaggle movie.csv'\n",
    "CSV\n",
    "HEADER\n",
    "QUOTE '\"'\n",
    "DELIMITER ',';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now checking whether all the rows are pulled into the kaggle_data table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT COUNT(*) FROM kaggle_data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT  DISTINCT movie_name,duration,gross,budget,facebook_likes,average_rating \n",
    "FROM avg_ratings a LEFT JOIN kaggle_data k ON \n",
    "TRIM(a.movie_name)=TRIM(k.movie_title) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "COPY(SELECT DISTINCT movie_name,duration,gross,budget,facebook_likes,average_rating \n",
    "FROM avg_ratings a LEFT JOIN kaggle_data k ON \n",
    "TRIM(a.movie_name)=TRIM(k.movie_title) ) TO '/home/rithvik/prog/finalproj/missing_train.csv' CSV HEADER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see some missing data for the movies which we are interested. So we find the data online for the missing movies and reload it into the table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS final_train;\n",
    "CREATE TABLE final_train(\n",
    "movie_name VARCHAR (200),\n",
    "duration NUMERIC,\n",
    "gross NUMERIC,\n",
    "budget NUMERIC,\n",
    "facebook_likes NUMERIC,\n",
    "average_rating NUMERIC);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "COPY final_train FROM '/home/rithvik/prog/finalproj/final_train.csv'\n",
    "CSV\n",
    "HEADER\n",
    "QUOTE '\"'\n",
    "DELIMITER ',';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TABLE IF EXISTS twitter_train;\n",
    "CREATE TABLE twitter_train(\n",
    "movie_name VARCHAR (200),\n",
    "sentiment_score NUMERIC,\n",
    "nominated NUMERIC);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "COPY twitter_train FROM '/home/rithvik/prog/finalproj/twitter_train.csv'\n",
    "CSV\n",
    "HEADER\n",
    "QUOTE '\"'\n",
    "DELIMITER ',';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we join the final training data which contains the attributes like duration,gross,budget, facebook likes and average rating with the twitter data which contains twitter sentiment score and whether the movie is nominated or not "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT f.movie_name,f.duration,f.gross,f.budget,f.facebook_likes,f.average_rating,t.sentiment_score,t.nominated\n",
    "FROM final_train f JOIN twitter_train t ON\n",
    "TRIM(f.movie_name)=TRIM(t.movie_name);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now exporting the final train table inorder to model this data in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "COPY (SELECT f.movie_name,f.duration,f.gross,f.budget,f.facebook_likes,f.average_rating,t.sentiment_score,t.nominated\n",
    "FROM final_train f JOIN twitter_train t ON\n",
    "TRIM(f.movie_name)=TRIM(t.movie_name)) TO '/home/rithvik/prog/finalproj/movie_train.csv' CSV HEADER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "working on validation data, we make 2015 data as validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT i.movie_name,i.rating AS IMDB_Rating,r.rating AS Rotten_Tomatoes_Rating,cast((((i.rating*10)+r.rating)/2) as Integer) AS Average_rating\n",
    "FROM imdb_2015 i JOIN rotten_2015 r \n",
    "ON TRIM(i.movie_name)=TRIM(r.movie_name);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "COPY (SELECT i.movie_name,i.rating AS IMDB_Rating,r.rating AS Rotten_Tomatoes_Rating,cast((((i.rating*10)+r.rating)/2) as Integer) AS Average_rating\n",
    "FROM imdb_2015 i JOIN rotten_2015 r \n",
    "ON TRIM(i.movie_name)=TRIM(r.movie_name)) TO '/home/rithvik/prog/finalproj/movie_2015.csv' CSV HEADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TABLE IF EXISTS val_avgratings;\n",
    "CREATE TABLE val_avgratings as\n",
    "SELECT i.movie_name,i.rating AS IMDB_Rating,r.rating AS Rotten_Tomatoes_Rating,cast((((i.rating*10)+r.rating)/2) as Integer) AS Average_rating\n",
    "FROM imdb_2015 i JOIN rotten_2015 r \n",
    "ON TRIM(i.movie_name)=TRIM(r.movie_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now joining the baove table with kaggle data to get the budget ,gross, fb likes etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT  DISTINCT movie_name,duration,gross,budget,facebook_likes,average_rating \n",
    "FROM val_avgratings a Left JOIN kaggle_data k ON \n",
    "TRIM(a.movie_name)=TRIM(k.movie_title);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS final_val;\n",
    "CREATE TABLE final_val(\n",
    "movie_name VARCHAR (200),\n",
    "duration NUMERIC,\n",
    "gross NUMERIC,\n",
    "budget NUMERIC,\n",
    "facebook_likes NUMERIC,\n",
    "average_rating NUMERIC);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "COPY final_val FROM '/home/rithvik/prog/finalproj/final_val.csv'\n",
    "CSV\n",
    "HEADER\n",
    "QUOTE '\"'\n",
    "DELIMITER ',';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TABLE IF EXISTS twitter_val;\n",
    "CREATE TABLE twitter_val(\n",
    "movie_name VARCHAR (200),\n",
    "sentiment_score NUMERIC,\n",
    "nominated NUMERIC);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "COPY twitter_val FROM '/home/rithvik/prog/finalproj/twitter_val.csv'\n",
    "CSV\n",
    "HEADER\n",
    "QUOTE '\"'\n",
    "DELIMITER ',';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we join the final validation data which contains the attributes like duration,gross,budget, facebook likes and average rating with the twitter data which contains twitter sentiment score and whether the movie is nominated or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT f.movie_name,f.duration,f.gross,f.budget,f.facebook_likes,f.average_rating,t.sentiment_score,t.nominated\n",
    "FROM final_val f JOIN twitter_val t ON\n",
    "TRIM(f.movie_name)=TRIM(t.movie_name);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "COPY(SELECT f.movie_name,f.duration,f.gross,f.budget,f.facebook_likes,f.average_rating,t.sentiment_score,t.nominated\n",
    "FROM final_val f JOIN twitter_val t ON\n",
    "TRIM(f.movie_name)=TRIM(t.movie_name)) TO '/home/rithvik/prog/finalproj/movie_val.csv' CSV HEADER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we work on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TABLE IF EXISTS imdb_2016;\n",
    "\n",
    "CREATE TABLE imdb_2016(\n",
    "id SERIAL,\n",
    "movie_name VARCHAR(100),\n",
    "rating NUMERIC\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "COPY imdb_2016 FROM '/home/rithvik/prog/finalproj/imdb_2016.csv'\n",
    "CSV\n",
    "HEADER\n",
    "QUOTE '\"'\n",
    "DELIMITER ',';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TABLE IF EXISTS rotten_2016;\n",
    "\n",
    "CREATE TABLE rotten_2016(\n",
    "id SERIAL,\n",
    "movie_name VARCHAR(100),\n",
    "rating NUMERIC\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "COPY rotten_2016 FROM '/home/rithvik/prog/finalproj/rotten_2016.csv'\n",
    "CSV\n",
    "HEADER\n",
    "QUOTE '\"'\n",
    "DELIMITER ',';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now joining the data and computing the average rating for 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT i.movie_name,i.rating AS IMDB_Rating,r.rating AS Rotten_Tomatoes_Rating,cast((((i.rating*10)+r.rating)/2) as Integer) AS Average_rating\n",
    "FROM imdb_2016 i JOIN rotten_2016 r \n",
    "ON TRIM(i.movie_name)=TRIM(r.movie_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TABLE IF EXISTS test_avgratings;\n",
    "CREATE TABLE test_avgratings as\n",
    "SELECT i.movie_name,i.rating AS IMDB_Rating,r.rating AS Rotten_Tomatoes_Rating,cast((((i.rating*10)+r.rating)/2) as Integer) AS Average_rating\n",
    "FROM imdb_2016 i JOIN rotten_2016 r \n",
    "ON TRIM(i.movie_name)=TRIM(r.movie_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT movie_name,duration,gross,budget,facebook_likes,average_rating \n",
    "FROM test_avgratings a Left JOIN kaggle_data k ON \n",
    "TRIM(a.movie_name)=TRIM(k.movie_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "COPY(SELECT movie_name,duration,gross,budget,facebook_likes,average_rating \n",
    "FROM test_avgratings a Left JOIN kaggle_data k ON \n",
    "TRIM(a.movie_name)=TRIM(k.movie_title)) TO '/home/rithvik/prog/finalproj/movie_test_2016.csv' CSV HEADER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see some missing data for the movies which we are interested. So we find the data online for the missing movies and reload it into the table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS final_test;\n",
    "CREATE TABLE final_test(\n",
    "movie_name VARCHAR (200),\n",
    "duration NUMERIC,\n",
    "gross NUMERIC,\n",
    "budget NUMERIC,\n",
    "facebook_likes NUMERIC,\n",
    "average_rating NUMERIC);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "COPY final_test FROM '/home/rithvik/prog/finalproj/final_test.csv'\n",
    "CSV\n",
    "HEADER\n",
    "QUOTE '\"'\n",
    "DELIMITER ',';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TABLE IF EXISTS twitter_test;\n",
    "CREATE TABLE twitter_test(\n",
    "movie_name VARCHAR (200),\n",
    "sentiment_score NUMERIC,\n",
    "nominated NUMERIC);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "COPY twitter_test FROM '/home/rithvik/prog/finalproj/twitter_test.csv'\n",
    "CSV\n",
    "HEADER\n",
    "QUOTE '\"'\n",
    "DELIMITER ',';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we join the final training data which contains the attributes like duration,gross,budget, facebook likes and average rating with the twitter data which contains twitter sentiment score and whether the movie is nominated or not\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT f.movie_name,f.duration,f.gross,f.budget,f.facebook_likes,f.average_rating,t.sentiment_score,t.nominated\n",
    "FROM final_test f JOIN twitter_test t ON\n",
    "TRIM(f.movie_name)=TRIM(t.movie_name);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "COPY(SELECT f.movie_name,f.duration,f.gross,f.budget,f.facebook_likes,f.average_rating,t.sentiment_score,t.nominated\n",
    "FROM final_test f JOIN twitter_test t ON\n",
    "TRIM(f.movie_name)=TRIM(t.movie_name)) TO '/home/rithvik/prog/finalproj/movie_test.csv' CSV HEADER"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
